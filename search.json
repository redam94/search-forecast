[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "search-forecast",
    "section": "",
    "text": "This file will become your README and also the index of your documentation.",
    "crumbs": [
      "search-forecast"
    ]
  },
  {
    "objectID": "index.html#developer-guide",
    "href": "index.html#developer-guide",
    "title": "search-forecast",
    "section": "Developer Guide",
    "text": "Developer Guide\nIf you are new to using nbdev here are some useful pointers to get you started.\n\nInstall search_forecast in Development mode\n# make sure search_forecast package is installed in development mode\n$ pip install -e .\n\n# make changes under nbs/ directory\n# ...\n\n# compile to have changes apply to search_forecast\n$ nbdev_prepare",
    "crumbs": [
      "search-forecast"
    ]
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "search-forecast",
    "section": "Usage",
    "text": "Usage\n\nInstallation\nInstall latest from the GitHub repository:\n$ pip install git+https://github.com/redam94/search-forecast.git\n\n\nDocumentation\nDocumentation can be found hosted on this GitHub repository’s pages.",
    "crumbs": [
      "search-forecast"
    ]
  },
  {
    "objectID": "wrapper/pymc_wrapper.html",
    "href": "wrapper/pymc_wrapper.html",
    "title": "PyMC Wrapper",
    "section": "",
    "text": "source\n\nHSGP\n\n HSGP (name:str, **kwargs)\n\nGeneralized prior interface for pymc-marketing. This generalizes the use of the apply method to any prior.\n\nhspg = HSGP(\n    \"hspg\",\n    m=40,\n    ls=1,\n    eta=3,\n    L=60,\n    dims=(\"date\",)\n)\n\n\nsource\n\n\nHSGPPeriodic\n\n HSGPPeriodic (name:str, **kwargs)\n\nGeneralized prior interface for pymc-marketing. This generalizes the use of the apply method to any prior.\n\nsource\n\n\nYearlyFourier\n\n YearlyFourier (name:str, **kwargs)\n\nGeneralized prior interface for pymc-marketing. This generalizes the use of the apply method to any prior.\n\nyearly_fourier = YearlyFourier(\n    name=\"yearly_fourier\",\n    n_order=3,\n    dims=(\"date\",),\n)\n\n\n\n\nFourierBase.sample_prior\n\n FourierBase.sample_prior (coords:dict|None=None, **kwargs)\n\nSample the prior distributions.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ncoords\ndict | None\nNone\nCoordinates for the prior distribution, by default None\n\n\nkwargs\nVAR_KEYWORD\n\nAdditional keywords for sample_prior_predictive\n\n\nReturns\nDataset\n\nPrior distribution.\n\n\n\n\n\n\nFourierBase.sample_curve\n\n FourierBase.sample_curve (parameters:arviz.data.inference_data.InferenceD\n                           ata|xarray.core.dataset.Dataset,\n                           use_dates:bool=False,\n                           start_date:str|datetime.datetime|None=None)\n\nCreate full period of the Fourier seasonality.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nparameters\narviz.data.inference_data.InferenceData | xarray.core.dataset.Dataset\n\nInference data or dataset containing the Fourier parameters.Can be posterior or prior.\n\n\nuse_dates\nbool\nFalse\nIf True, use datetime coordinates for the x-axis. Defaults to False.\n\n\nstart_date\nstr | datetime.datetime | None\nNone\nStarting date for the Fourier curve. If not provided and use_dates is True,it will be derived from the current year or month. Defaults to None.\n\n\nReturns\nDataArray\n\nFull period of the Fourier seasonality.\n\n\n\n\nprior_sample = yearly_fourier.sample_prior(coords={\"date\": np.arange(0, 365)})\ncurve_sample = yearly_fourier.sample_curve(prior_sample)\ncurve_sample.sel(chain=0, draw=slice(10)).plot(x='day', hue='draw');\n\nSampling: [yearly_fourier_beta]\nSampling: []\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsource\n\n\nWeeklyFourier\n\n WeeklyFourier (name:str, **kwargs)\n\nGeneralized prior interface for pymc-marketing. This generalizes the use of the apply method to any prior.\n\nsource\n\n\nPrior\n\n Prior (name:str, **kwargs)\n\nGeneralized prior interface for pymc-marketing. This generalizes the use of the apply method to any prior.\n\nsource\n\n\nData\n\n Data (name:str, dims:Optional[Tuple[str]]=None)\n\nGeneralized prior interface for pymc-marketing. This generalizes the use of the apply method to any prior.",
    "crumbs": [
      "wrapper",
      "PyMC Wrapper"
    ]
  },
  {
    "objectID": "model/search_model.html",
    "href": "model/search_model.html",
    "title": "Search Model",
    "section": "",
    "text": "source\n\nImpressionPrior\n\n ImpressionPrior (value, names=None, module=None, qualname=None,\n                  type=None, start=1)\n\nEnum for prior distributions of impressions.\n\nsource\n\n\nImpressionModel\n\n ImpressionModel (dims:tuple[str],\n                  priors:dict[__main__.ImpressionPrior,dict[str,str|float]\n                  ]|None=None)\n\nA class to represent the impression model.",
    "crumbs": [
      "model",
      "Search Model"
    ]
  },
  {
    "objectID": "utils/data_gen.html",
    "href": "utils/data_gen.html",
    "title": "Data Generation",
    "section": "",
    "text": "source\n\nhill\n\n hill (x:numpy.ndarray, half_sat:float, slope:float)\n\nHill function for dose-response curves.\n\nsource\n\n\ngenerate_data_search_data\n\n generate_data_search_data (n_days:int=400, n_geos:int=10, seed:int=42,\n                            start_date:str='2020-01-01', budget=None)",
    "crumbs": [
      "utils",
      "Data Generation"
    ]
  },
  {
    "objectID": "examples/search_prediction.html",
    "href": "examples/search_prediction.html",
    "title": "Search Forecasting",
    "section": "",
    "text": "This document presents a formal analysis of our probabilistic search advertising model, demonstrating how it effectively captures the relationship between marketing expenditure and business outcomes. Using synthetic data that mirrors real-world advertising patterns, we illustrate the model’s structure, statistical properties, and practical applications for optimizing advertising investments.",
    "crumbs": [
      "examples",
      "Search Forecasting"
    ]
  },
  {
    "objectID": "examples/search_prediction.html#introduction-the-search-advertising-journey",
    "href": "examples/search_prediction.html#introduction-the-search-advertising-journey",
    "title": "Search Forecasting",
    "section": "Introduction: The Search Advertising Journey",
    "text": "Introduction: The Search Advertising Journey\nSearch advertising represents a complex ecosystem where multiple factors interact to determine your business outcomes. At its core, the process follows this path:\n\nUsers search for terms related to your products or services\nYour budget competes for visibility among these searches\nImpressions are generated when your ads appear in search results\nUsers click on a portion of these impressions, driving traffic to your site\n\nWhile this flow seems straightforward, accurately modeling and predicting these relationships is challenging. Traditional approaches often make simplistic assumptions that don’t capture real-world complexities:\n\nLinear models incorrectly assume doubling your budget doubles your results\nSingle-factor models miss the interplay between seasonality, geography, and competition\nDeterministic approaches fail to account for inherent uncertainty in user behavior\n\nOur Bayesian hierarchical model overcomes these limitations by respecting the true causal structure of search advertising and quantifying uncertainty at each step.",
    "crumbs": [
      "examples",
      "Search Forecasting"
    ]
  },
  {
    "objectID": "examples/search_prediction.html#the-causal-structure-understanding-what-drives-what",
    "href": "examples/search_prediction.html#the-causal-structure-understanding-what-drives-what",
    "title": "Search Forecasting",
    "section": "The Causal Structure: Understanding What Drives What",
    "text": "The Causal Structure: Understanding What Drives What\nThe foundation of our model is a causal graph that represents how different variables influence each other:\n\n\n\n\n\n\n\n\nFigure 1: Causal graph for the search volume model.\n\n\n\n\n\nThis causal structure encodes several key insights:\n\nSearch volume is determined by time (seasonality) and geographic factors, not by your budget\nBudget directly influences impressions but has no direct effect on search volume\nImpressions are constrained by both budget and available search volume\nClicks come only from impressions, with rates influenced by time and geography\n\nThis separation of factors you control (budget) from those you don’t (market demand) provides clarity about what marketing levers you can pull and their expected effects.",
    "crumbs": [
      "examples",
      "Search Forecasting"
    ]
  },
  {
    "objectID": "examples/search_prediction.html#the-data-what-were-modeling",
    "href": "examples/search_prediction.html#the-data-what-were-modeling",
    "title": "Search Forecasting",
    "section": "The Data: What We’re Modeling",
    "text": "The Data: What We’re Modeling\nTo demonstrate the model, let’s examine some synthetic data that captures typical patterns in search advertising:\n\nSearch VolumeBudget AllocationImpressionsClicks\n\n\nThe Market Opportunity\n\n\n\n\n\n\n\n\nFigure 2: Search Volume across geographies, showing a strong seasonal patterns at both the weekly and yearly level.\n\n\n\n\n\nSearch volume represents the total market opportunity—how many people are searching for relevant terms. Notice in Figure 2:\n\nAnnual seasonality: In this example, peak volume occurs around April-May with lowest volume in September\nWeekly cycles: Regular oscillations show higher weekday searches and weekend drops\nThese patterns exist regardless of your advertising budget\n\n\n\nYour Strategic Decisions\n\n\n\n\n\n\n\n\nFigure 3: Budget allocation across geographies over time, showing a strong seasonal pattern and geos with little to no budget.\n\n\n\n\n\nBudget allocation shows how you’re distributing your advertising spend:\n\nVarying levels across different geographic regions\nSeasonal adjustments that often (but not always) mirror search volume patterns\nStrategic pauses where budget drops to zero in specific regions\n\n\n\nYour Market Visibility\n\n\n\n\n\n\n\n\nFigure 4: Impressions show a strong seasonal pattern and geos with little to no impressions.\n\n\n\n\n\nImpressions represent how many times your ads appear in search results:\n\nSeasonal patterns similar to search volume\nSharp drops to zero when budget is paused\nImmediate recovery when budget resumes\n\n\n\nYour success rate\n\n\n\n\n\n\n\n\nFigure 5: Synthetic click data.\n\n\n\n\n\nObserved clicks tend to have a seasonal and yearly patternd driven by the effects of search volume, search impressions and consumer behaviors. Notice:\n\nClicks drop to zero when impressions drop to zero\nStrong seasonal patterns are present at both weekly and yearly levels\n\n\n\n\n\nThe Budget-Results Relationship: Diminishing Returns\nThe relationship between budget and results (clicks/impressions) is clearly non-linear:\n\nInitial slow growth: At low budget levels (100-200), each additional dollar yields modest increases\nAcceleration phase: At middle budget ranges (200-300), returns improve\nDiminishing returns: At higher levels (400+), additional spending faces decreasing efficiency\nVariability: Even at the same budget level, results vary due to seasonal factors\n\nThis non-linear pattern reflects real-world marketplace dynamics, where competition and saturation limit the effectiveness of additional spending.\n\nBudget-ImpressionsClick Response to Budget\n\n\n\n\n\n\n\n\n\n\nFigure 6: Observed relationship between budget and impressions.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 7: Observed relationship between budget and observed clicks.",
    "crumbs": [
      "examples",
      "Search Forecasting"
    ]
  },
  {
    "objectID": "examples/search_prediction.html#the-model-structure-four-interconnected-components",
    "href": "examples/search_prediction.html#the-model-structure-four-interconnected-components",
    "title": "Search Forecasting",
    "section": "The Model Structure: Four Interconnected Components",
    "text": "The Model Structure: Four Interconnected Components\nOur forecasting system models this process through 4 interconnected components, each with its own statistical approach:\n\nDefining Inputs and Statistical Controls\n\nBuild components for seasonality and trends\nAccount for different base levels for different geographies\nAdd noise to account for shocks\n\nSearch Volume Forecasting\n\nProjects underlying market demand independent of your advertising\nAccounts for both weekly cycles and yearly seasonality\nAdjusts for geographic differences in search behavior\n\nImpression Generation\n\nModels how your budget converts search volume into impressions\nCaptures the “hill function” effect where budget increases face diminishing returns\nIdentifies periods of zero impressions when budget is paused\n\nClick-Through Prediction\n\nEstimates conversion from impressions to valuable clicks\nAccounts for seasonal variations in consumer engagement\nReflects geographic differences in click behavior\n\n\n\n1. Defining Inputs and Statistical Controls\nLooking at the causal graph (Figure 1), we can see how information flows through the model:\n\nExternal Factors First: Time and geography are the foundation variables that influence everything else\nSearch Volume Generation: These external factors determine how many people search for relevant terms\nBudget Allocation: Your marketing spend determines what portion of searches become impressions\nConversion Process: Impressions then convert to clicks based on various factors\n\nThis structure accurately represents real-world advertising dynamics where you can control your budget but not consumer search behavior.\n\n\n\n\nListing 1: Define the main inputs to the model for this example only time and budget are used.\n\n\n# Date to be used as a time index in the model \ntime_data = Data('time', dims=('date')) \n\n# Budget to be used as a covariate in the model\nbudget_data = Data('budget', dims=('date', 'geo'))\n\n\n\n\nStatistical controls can be used when data or theory is not available to ascribe cause to any particular variable. They allow use to seperate noise and things outside our control from the factors we are interested in studying (budget allocation). If theory suggests other explanatory variables for which data is available that explain the variation in the data they should be used instead.\n\n\n\n\nListing 2: Define a long-term periodicity prior for the model.\n\n\n# Length scale prior for the long-term periodicity\n# The length scale defines the smoothness of the periodic function\n# A small length scale means that the function will vary quickly, \n# while a large length scale means that the function will vary slowly\n# The length scale is a hyperparameter that can be learned from the data\n# Because the length scale is positive, we use a gamma prior\nls_long_periodic = Prior(\n    'ls_lp', \n    prior_name=\"Gamma\", \n    alpha=1, \n    beta=1/5\n)\n\n# Scale prior for the long-term periodicity\n# The scale defines the amplitude of the periodic function\n# A small scale means that the function will be small,\n# while a large scale means that the function will be large\n# The scale is a hyperparameter that can be learned from the data\n# Because the scale is positive and it may be large, we use an exponential prior\nscale_long_periodic = Prior(\n    'scale_lp',\n    prior_name=\"Exponential\",\n    lam=1/100.0)\n\n# A Gaussian process prior for the long-term periodicity\n# This prior is used to model time-varying effects\n# This allows for the model to capture long-term trends in the data\nlong_periodic = HSGPPeriodic(\n    \"long_term_periodic\",\n    m=40, # Rank of the GP approximation\n    ls=ls_long_periodic,\n    scale=scale_long_periodic,\n    dims=('date', 'geo'), # Varies by date and geo\n    period=365 # yearly \n)\n\n\n\n\n\n\n\n\nListing 3: Define a long-term periodicity prior for click-through-rate (CTR). This allows for the model to capture long-term trends in the CTR data separately from the impressions data.\n\n\n# Hyperparameters for the long-term periodicity prior for CTR\nls_long_periodic_ctr = Prior(\n    \"ls_lp_ctr\",\n    prior_name=\"Gamma\", \n    alpha=1, \n    beta=1/5\n    )\nscale_long_periodic_ctr = Prior(\n    \"scale_lp_ctr\", \n    prior_name=\"Exponential\", \n    lam=1\n    )\n\nlong_periodic_ctr = HSGPPeriodic(\n    \"long_term_periodic_ctr\",\n    m=40,\n    ls=ls_long_periodic_ctr,\n    scale=scale_long_periodic_ctr,\n    dims=('date', 'geo'),\n    period=365 # yearly\n)\n\n\n\n\n\n\n\n\nListing 4: Define a weekly periodicity prior for the model. Fourier basis functions are used to model the weekly periodicity.\n\n\n# Weekly periodic component\nweekly_periodic = WeeklyFourier(\n    name='weekly_periodic',\n    n_order=3, # Number of Fourier basis functions to use\n    prefix='weekly_search_volume',\n    dims=('date',)\n    )\n\n\n\n\n\n\n\n\nListing 5: Define a short-term periodicity prior for CTR. Assumes a weekly periodicity which may be different from the weekly periodicity of the impressions.\n\n\nls_short_periodic = Prior(\"ls_sp\", prior_name=\"Gamma\", alpha=1, beta=1/30)\nscale_short_periodic = Prior(\"scale_sp\", prior_name=\"Exponential\", lam=1)\n\nshort_periodic_ctr= HSGPPeriodic(\n    \"short_term_periodic_ctr\",\n    m=40,\n    ls=ls_long_periodic,\n    scale=scale_long_periodic,\n    dims=('date', 'geo'),\n    period=7 # weekly\n)\n\n\n\n\n\n\n\n\nListing 6: Define a hierarchical prior for geographic effects for the search volume. This allows for the model to capture geographic effects in the search volume data.\n\n\n# Average search volume over all geographies\nmean_search_volume = Prior(\n            \"base_volume_mu\", \n            prior_name=\"Normal\", \n            mu=22000, \n            sigma=8000\n)\n\n# Hyperparameters for the amount of pooling between geographies\namount_of_pooling_volume = Prior(\n        \"base_volume_sigma\", \n        prior_name=\"HalfNormal\", \n        sigma=500\n)\n\n# Random effects by geo for the search volume\nvolume_random_effects = Prior(\n        \"base_volume_random_effects\",\n        prior_name=\"Normal\",\n        mu=0,\n        sigma=amount_of_pooling_volume,\n        dims=('geo',)\n    )\n\nbase_volume = (mean_search_volume + volume_random_effects)\n\n\n\n\n\n\n\n\nListing 7: Search volume may be affected by shocks. These are small random variations in the search volume data at the day and geo level.\n\n\ndaily_geo_shocks_search_volume = Prior(\n        \"daily_geo_shocks_search_volume\",\n        prior_name=\"Normal\", \n        mu=0, \n        sigma=Prior(\n            \"daily_geo_shocks_search_volume_scale\", \n            prior_name=\"HalfCauchy\", \n            beta=1\n        ), \n        dims=('date', 'geo')\n    )\n\n\n\n\n\n\n2. Search Volume Component\nThis predicts the underlying market demand:\n\nBase Volume: A normal distribution representing the average search volume for each geographic region Code 6\nTemporal Patterns:\n\nWeekly seasonal components (captured by Fourier series Code 4)\nLong-term periodic components (captured by Hilbert Space Gaussian Processes Code 2)\n\nGeographic Variations: Random effects that account for differences between markets Code 6\nDaily Shocks: Random variations that capture unexpected search behavior fluctuations Code 7\n\nThe model assumes search volume follows a Poisson distribution, which is ideal for count data and allows for appropriate variance as volume increases. Code 9\n\n\n\n\nListing 8: Define the model for the mean search volume. This is a linear model with a long-term periodicity, weekly periodicity, geographic effects and daily shocks.\n\n\n# The mean search volume must be positive, so we use a softplus transformation \n# an exponential transformation could also be used but then all the priors must be \n# in the log domain\n# The softplus transformation is a smooth approximation of the ReLU function\nsearch_volume_lam = ((\n    long_periodic \n    + weekly_periodic\n    + base_volume\n    + daily_geo_shocks_search_volume\n    )(time_data)).transform(pt.softplus)\n\n\n\n\n\n\n\n\nListing 9: Define the model for the observed search volume. This is a Poisson distribution with a mean defined by the search volume model.\n\n\nwith pm.Model(coords=coords) as search_model:\n    lam = handle_dims(\n        search_volume_lam.apply(time_index), \n        search_volume_lam._dims, \n        (\"date\", \"geo\")\n    )\n    search_volume_obs = pm.Poisson(\n        \"search_volume_obs\",\n        mu=lam,\n        dims=(\"date\", \"geo\"),\n    )\n\n\n\n\n\n\n\n\n\n\nKey assumptions and justifications:\n\n\n\n\nPoisson distribution for search volume: Appropriate for count data with variance proportional to the mean\nGaussian Process priors for seasonality: Allows flexible modeling of complex patterns without rigid assumptions\nHierarchical structure for geographic effects: Shares information across regions while allowing for differences\nAdditive components: Each factor (weekly patterns, yearly seasonality, etc.) contributes independently to the overall trend\n\n\n\n\nSimulated Search VolumeAverage Simulated Search Volume and Prediction Interval\n\n\n\n\n\n\n\n\n\n\nFigure 8: Simulated search volume from the model.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 9: Simulated search volume from the model.\n\n\n\n\n\n\n\n\n\n\n3. Impression Generation Model\nThis component converts search volume to impressions based on your budget:\n\nBudget Effect: Uses a weighted hill function (shown in the code as budget_transform(multiplier, competitor_pressure, budget) Code 11)\nCompetitor Pressure: A Half-Cauchy distribution parameter that models how difficult it is to win impressions Code 10\nImpression Rate: The probability that a search will result in your ad being shown Code 12\nFinal Impressions: Modeled as a Binomial distribution (either shown or not shown) Code 13\n\nThis structure captures the diminishing returns seen in Figure 6, Figure 7, where doubling your budget doesn’t double your results.\n\n\n\n\nListing 10: Define the priors for the budget model.\n\n\n# The max precentage of search volume that can be converted to impressions\n# Must be between 0 and 1\nmultiplier = Prior(\n    \"search_volume_multiplier\", \n    prior_name=\"Beta\", \n    alpha=0.5, \n    beta=0.5, \n    dims=tuple()\n    )\n\n# The average competitive pressure for bidded keywords\n# This can be modeled by keword category, by geo and time\n# It is assumed constant for simplicity\n# Must be positive but can be large\ncompetitor_pressure = Prior(\n    \"competitor_pressure\", \n    prior_name=\"HalfCauchy\", \n    beta=1, \n    dims=tuple()\n    )\n\n\n\n\n\n\n\n\nListing 11: Define a nonlinear hill transformation for the budget model.\n\n\ndef budget_transform(multiplier, competitor_pressure, budget):\n    numerator = multiplier * budget\n    denominator = budget + competitor_pressure\n    return numerator / denominator\n\n\n\n\n\n\n\n\nListing 12: Define the model for the impression rate. This is a nonlinear transformation of the budget data.\n\n\nimpression_rate = budget_transform(\n    multiplier=multiplier,\n    competitor_pressure=competitor_pressure,\n    budget=budget_data\n)\n\n\n\n\n\n\n\n\nListing 13: Define the model for the observed impressions.\n\n\nwith search_model:\n    imp_rate = handle_dims(\n        impression_rate.apply(obs_budget_data), \n        impression_rate._dims, \n        (\"date\", \"geo\"))\n    impressions_obs = pm.Binomial(\n        \"impressions_obs\",\n        n=search_volume_obs,\n        p=imp_rate,\n        dims=(\"date\", \"geo\"),\n    )\n\n\n\n\n\n\n\n\n\n\nKey assumptions and justifications:\n\n\n\n\nHill function for budget effects: Creates an S-shaped curve that realistically models marketplace dynamics\nCompetitor pressure parameter: Captures how difficult it is to win impression share in competitive markets\nBinomial distribution for impressions: Models the binary outcome (shown/not shown) for each potential search\nUpper bound constrained by search volume: You can’t get more impressions than there are searches\n\n\n\n\nPrior Simulated ImpressionsAverage Impressions\n\n\n\n\n\n\n\n\n\n\nFigure 10: Simulated search volume from the model. Note that when budget is 0, impressions are also 0.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 11: Simulated impressions from the model.\n\n\n\n\n\n\n\n\n\n\n4. Click-Through Rate Model\nThis predicts how impressions convert to clicks:\n\nBase CTR: The fundamental click probability Code 14\nTemporal CTR Patterns:\n\nShort-term periodic effects (customer behavior trends) Code 14\nLong-term periodic effects (seasonal buying patterns) Code 14\n\nFinal Clicks: Modeled as a Binomial distribution based on these probabilities Code 15\n\n\n\n\n\nListing 14: Define the CTR model.\n\n\nbase_ctr = Prior(\n    \"base_ctr\", \n    prior_name=\"Normal\", \n    mu=0, \n    sigma=1\n)\n\nnoise = Prior(\n    \"ctr_noise\", \n    prior_name=\"Normal\", \n    sigma=Prior(\n        \"ctr_noise_scale\", \n        prior_name=\"HalfNormal\", \n        sigma=.01,\n        dims=tuple()\n    ),\n    dims=(\"date\",)\n)\n\nctr = ((\n    short_periodic_ctr \n    + long_periodic_ctr \n    + base_ctr\n    + noise\n)(time_data)\n).transform(pt.sigmoid)\n\n\n\n\n\n\n\n\nListing 15: Define the model for the observed clicks.\n\n\nwith search_model:\n    ctr = handle_dims(\n        ctr.apply(obs_budget_data), \n        ctr._dims, \n        (\"date\", \"geo\"))\n    clicks_obs = pm.Binomial(\n        \"clicks_obs\",\n        n=impressions_obs,\n        p=ctr,\n        dims=(\"date\", \"geo\"),\n    )\n\n\n\n\n\n\n\n\n\n\nKey assumptions and justifications:\n\n\n\n\nSigmoid transformation: Ensures click probabilities stay between 0 and 1\nBinomial distribution for clicks: Models the binary outcome (clicked/not clicked) for each impression\nTemporal components: Captures how user behavior varies by day of week and season\nHierarchical structure: Allows for geographic differences in click behavior\n\n\n\n\nPrior Simulated ClicksAverage Clicks\n\n\n\n\n\n\n\n\n\n\nFigure 12: Simulated search clicks from the model. Note that when budget is 0, clicks are also 0.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 13: Simulated clicks from the model.",
    "crumbs": [
      "examples",
      "Search Forecasting"
    ]
  },
  {
    "objectID": "examples/search_prediction.html#the-complete-probabilistic-model",
    "href": "examples/search_prediction.html#the-complete-probabilistic-model",
    "title": "Search Forecasting",
    "section": "The Complete Probabilistic Model",
    "text": "The Complete Probabilistic Model\nThe full model integrates all these components in a Bayesian framework:\n\n\n\n\n\n\n\n\nFigure 14: Full PyMC model for the search volume and impressions data.\n\n\n\n\n\nThis probabilistic approach offers several advantages:\n\nUncertainty quantification: Provides confidence intervals around predictions\nParameter learning: Infers key parameters like competitor pressure from your historical data\nFuture forecasting: Projects expected performance under different budget scenarios\nAnomaly detection: Identifies when performance diverges from expectations",
    "crumbs": [
      "examples",
      "Search Forecasting"
    ]
  },
  {
    "objectID": "examples/search_prediction.html#fitting-the-model",
    "href": "examples/search_prediction.html#fitting-the-model",
    "title": "Search Forecasting",
    "section": "Fitting the Model",
    "text": "Fitting the Model\n\ndef partial_observe(model, obs_data, input_data, coords, target_accept=.70):\n    with pm.observe(model, obs_data):\n        pm.set_data(input_data, coords=coords)\n        trace = pm.sample(1000, tune=1000, target_accept=target_accept, nuts_sampler='nutpie')\n    return trace\n\nsearch_volume_trace = partial_observe(\n    search_model, \n    {'search_volume_obs': train_data.search_volume.values,\n    'impressions_obs': train_data.impressions.values,\n    'clicks_obs': train_data.observed_clicks.values}, \n    {'time': train_data['time'].values,\n    'budget': train_data.budget.values}, \n    coords,\n    target_accept=.95\n    )\n\n\n\n\n\n\n\n    Sampler Progress\n    Total Chains: 4\n    Active Chains: 0\n    \n        Finished Chains:\n        4\n    \n    Sampling for 5 minutes\n    \n        Estimated Time to Completion:\n        now\n    \n\n    \n    \n    \n        \n            \n                Progress\n                Draws\n                Divergences\n                Step Size\n                Gradients/Draw\n            \n        \n        \n            \n                \n                    \n                        \n                        \n                    \n                    2000\n                    0\n                    0.03\n                    1023\n                \n            \n                \n                    \n                        \n                        \n                    \n                    2000\n                    0\n                    0.02\n                    1023\n                \n            \n                \n                    \n                        \n                        \n                    \n                    2000\n                    0\n                    0.03\n                    1023\n                \n            \n                \n                    \n                        \n                        \n                    \n                    2000\n                    0\n                    0.03\n                    127\n                \n            \n            \n        \n    \n\n\n\n\nsearch_volume_pred = predict_full_period(search_volume_trace)\n\nSampling: [clicks_obs, ctr_noise, daily_geo_shocks_search_volume, impressions_obs, search_volume_obs]\n\n\n\n\n\n\n\n\n\nForecast Results\n\nSearch VolumeSearch ImpressionsClicks\n\n\n\n\n\n\n\n\n\n\nFigure 15: Forecasted search volume. The model captures the seasonal patterns in the data and the uncertainty in the forecast. The model forecast is accurate for the first 30 days after the training data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 16: Forecasted impressions. The model captures the seasonal patterns in the data and the uncertainty in the forecast. The model forecast is accurate for the first 30 days after the training data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 17: Forecasted impressions. The model captures the seasonal patterns in the data and the uncertainty in the forecast. The model forecast is accurate for the first 30 days after the training data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPosterior estimate for the function parameters relating budget to impressions.\n\n\n\nmean\nsd\nhdi_3%\nhdi_97%\nmcse_mean\nmcse_sd\ness_bulk\ness_tail\nr_hat\n\n\n\n\nsearch_volume_multiplier\n0.251\n0.002\n0.248\n0.254\n0.000\n0.00\n599.0\n893.0\n1.01\n\n\ncompetitor_pressure\n30.320\n0.415\n29.569\n31.139\n0.017\n0.01\n592.0\n899.0\n1.01\n\n\n\n\n\n\n\n\nModel Updates\n\ntrain_data = data.isel(date=slice(None, 200))\nupdated_coords = {\n    \"date\": train_data.date.values,\n    \"geo\": train_data.geo.values\n}\nupdated_search_volume_trace = partial_observe(\n    search_model, \n    {'search_volume_obs': train_data.search_volume.values,\n    'impressions_obs': train_data.impressions.values,\n    'clicks_obs': train_data.observed_clicks.values}, \n    {'time': train_data['time'].values,\n    'budget': train_data.budget.values}, \n    updated_coords,\n    target_accept=.95\n    )\n\n\n\n\n\n\n\n    Sampler Progress\n    Total Chains: 4\n    Active Chains: 0\n    \n        Finished Chains:\n        4\n    \n    Sampling for 8 minutes\n    \n        Estimated Time to Completion:\n        now\n    \n\n    \n    \n    \n        \n            \n                Progress\n                Draws\n                Divergences\n                Step Size\n                Gradients/Draw\n            \n        \n        \n            \n                \n                    \n                        \n                        \n                    \n                    2000\n                    0\n                    0.03\n                    127\n                \n            \n                \n                    \n                        \n                        \n                    \n                    2000\n                    0\n                    0.03\n                    1023\n                \n            \n                \n                    \n                        \n                        \n                    \n                    2000\n                    0\n                    0.03\n                    127\n                \n            \n                \n                    \n                        \n                        \n                    \n                    2000\n                    0\n                    0.02\n                    1023\n                \n            \n            \n        \n    \n\n\n\n\nupdated_search_volume_pred = predict_full_period(updated_search_volume_trace)\n\nSampling: [clicks_obs, ctr_noise, daily_geo_shocks_search_volume, impressions_obs, search_volume_obs]\n\n\n\n\n\n\n\n\n\nSearch VolumeImpressionsClicks\n\n\n\n\n\n\n\n\n\n\nFigure 18: Forecasted search volume. The model captures the seasonal patterns in the data and the uncertainty in the forecast. The model forecast is accurate for the first 30 days after the training data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 19: Forecasted impressions. The model captures the seasonal patterns in the data and the uncertainty in the forecast. The model forecast is accurate for the first 30 days after the training data.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 20: Forecasted impressions. The model captures the seasonal patterns in the data and the uncertainty in the forecast. The model forecast is accurate for the first 30 days after the training data.",
    "crumbs": [
      "examples",
      "Search Forecasting"
    ]
  },
  {
    "objectID": "examples/search_prediction.html#practical-applications-optimizing-your-strategy",
    "href": "examples/search_prediction.html#practical-applications-optimizing-your-strategy",
    "title": "Search Forecasting",
    "section": "Practical Applications: Optimizing Your Strategy",
    "text": "Practical Applications: Optimizing Your Strategy\nThis model supports several critical business decisions:\n\nBudget Optimization\n\nFinding the inflection point: Identify where additional spending faces significantly diminishing returns\nScenario testing: Predict outcomes from different budget levels before committing resources\n\n\n\nGeographic Allocation\n\nMarket efficiency comparison: Identify which regions provide better returns on ad spend\nReallocation strategies: Shift budget from saturated to more responsive markets\n\n\n\nSeasonal Planning\n\nPreemptive adjustments: Increase budget before seasonal demand spikes\nEfficiency preservation: Reduce spending during predictable low-volume periods\n\n\n\nAnomaly Detection\n\nPerformance monitoring: Identify when actual results deviate from expectations\nCompetitive intelligence: Detect when marketplace dynamics change significantly",
    "crumbs": [
      "examples",
      "Search Forecasting"
    ]
  },
  {
    "objectID": "examples/search_prediction.html#limitations-and-considerations",
    "href": "examples/search_prediction.html#limitations-and-considerations",
    "title": "Search Forecasting",
    "section": "Limitations and Considerations",
    "text": "Limitations and Considerations\nLike all models this one is wrong, so it is important to understand the assumptions this model makes:\n\nCompetitor behavior assumptions: The model assumes competitor pressure changes slowly; rapid competitive shifts may reduce forecast accuracy\nMarket disruptions: Major external events (like a pandemic) may invalidate historical patterns\nNew market limitations: Limited historical data for new geographic regions may reduce forecast accuracy initially\nAttribution windows: The model assumes clicks are attributed to impressions within the same time window\n\nThis model is designed to be modular, so if any of these assumptions are violated in such a way that the model is no longer useful it can be ammended.",
    "crumbs": [
      "examples",
      "Search Forecasting"
    ]
  },
  {
    "objectID": "examples/search_prediction.html#next-steps-implementing-the-model",
    "href": "examples/search_prediction.html#next-steps-implementing-the-model",
    "title": "Search Forecasting",
    "section": "Next Steps: Implementing the Model",
    "text": "Next Steps: Implementing the Model\nTo implement this model for your business:\n\nData integration: Connect your search advertising platform data\nHistorical fitting: Train the model on your past performance\nScenario planning: Test different budget allocation strategies\nContinuous refinement: Update the model as new data becomes available",
    "crumbs": [
      "examples",
      "Search Forecasting"
    ]
  },
  {
    "objectID": "examples/search_prediction.html#conclusion-the-value-of-sophisticated-modeling",
    "href": "examples/search_prediction.html#conclusion-the-value-of-sophisticated-modeling",
    "title": "Search Forecasting",
    "section": "Conclusion: The Value of Sophisticated Modeling",
    "text": "Conclusion: The Value of Sophisticated Modeling\nTraditional approaches to search advertising often rely on simplistic assumptions that don’t capture real-world complexity. This probabilistic model overcomes these limitations by:\n\nRespecting causal structure: Distinguishing what you control from what you don’t\nCapturing non-linearity: Modeling diminishing returns and saturation effects\nAccounting for uncertainty: Providing confidence intervals around predictions\nIntegrating multiple factors: Combining seasonality, geography, and marketplace dynamics\n\nThis sophisticated approach provides more accurate forecasts and enables smarter budget allocation decisions across time periods and geographic markets.",
    "crumbs": [
      "examples",
      "Search Forecasting"
    ]
  }
]